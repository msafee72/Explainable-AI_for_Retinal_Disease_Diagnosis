{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10368227,"sourceType":"datasetVersion","datasetId":6421939}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nos.environ[\"WANDB_SILENT\"] = \"true\"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T18:00:22.588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport glob\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T18:00:22.588Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define Dataset Loading Function","metadata":{}},{"cell_type":"code","source":"def load_dataset(tfrecord_pattern, batch_size=64, shuffle=True):\n    # Get list of all TFRecord files in the directory\n    files = glob.glob(tfrecord_pattern)\n\n    # Define your feature description for parsing TFRecords\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),  # Serialized as bytes\n        'label': tf.io.FixedLenFeature([4], tf.int64)   # Assuming labels are one-hot encoded\n    }\n\n    # Function to parse the TFRecord examples\n    def _parse_function(proto):\n        parsed_example = tf.io.parse_single_example(proto, feature_description)\n        \n        # Decode image bytes to proper image tensor\n        image = tf.io.decode_jpeg(parsed_example['image'], channels=3)  # Adjust this to decode the image properly\n        image = tf.image.resize(image, (224, 224))  # Resize to match input shape\n        label = parsed_example['label']\n        return image, label\n\n    # Define the dataset\n    raw_dataset = tf.data.TFRecordDataset(files)\n    dataset = raw_dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n\n    # Optionally shuffle the data and batch it\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=1000)\n\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n    return dataset\n\n# Load the datasets\ntrain_dataset = load_dataset(\"/kaggle/input/oct-dataset-tfrecord/train/train_chunk_*.tfrecord\", batch_size=64)\nval_dataset = load_dataset(\"/kaggle/input/oct-dataset-tfrecord/val/val_chunk_*.tfrecord\", batch_size=64, shuffle=False)\ntest_dataset = load_dataset(\"/kaggle/input/oct-dataset-tfrecord/test/test_chunk_*.tfrecord\", batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T18:00:22.588Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set up Mirrored Strategy","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Initialize the strategy for multi-GPU training\nstrategy = tf.distribute.MirroredStrategy()\n\nprint(f\"Number of devices: {strategy.num_replicas_in_sync}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T18:00:22.588Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the Model and Wrap in Strategy Scope","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    from tensorflow.keras.applications import EfficientNetB7\n    from tensorflow.keras import layers, models\n\n    # Define the model\n    base_model = EfficientNetB7(\n        include_top=False,\n        weights='imagenet',  # Use pre-trained weights\n        input_shape=(224, 224, 3)\n    )\n\n    # Freeze the pre-trained layers\n    base_model.trainable = False\n\n    # Add custom head for classification\n    head_model = models.Sequential([\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(4, activation='softmax')  # Output 4 classes\n    ])\n\n    # Combine the base and custom head\n    final_model = models.Sequential([\n        base_model,\n        head_model\n    ])\n\n    # Compile the model\n    final_model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T18:00:22.589Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set up Callbacks for Checkpointing","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint_path = \"/kaggle/working/ckpt_{epoch:02d}.weights.h5\"\ncheckpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_path,\n    save_weights_only=True,\n    save_best_only=True,  # Save only the best model\n    monitor='val_loss',\n    mode='min',\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T18:00:22.589Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the Model","metadata":{}},{"cell_type":"code","source":"final_model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=50,  # Start with 50 epochs\n    callbacks=[checkpoint_callback]\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T18:00:22.589Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Adding Test Dataset","metadata":{}},{"cell_type":"code","source":"test_loss, test_accuracy = final_model.evaluate(test_dataset)\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Accuracy: {test_accuracy}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T18:00:22.589Z"}},"outputs":[],"execution_count":null}]}